import os
import warnings
import logging
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks, optimizers, applications, metrics
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt

# 1) Suprimir logs do TF
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.filterwarnings('ignore')
logging.getLogger('tensorflow').setLevel(logging.ERROR)

# 2) Carregar dataset 80/20
AUTOTUNE = tf.data.AUTOTUNE
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    'dataset', validation_split=0.2, subset='training',
    seed=123, image_size=(224,224), batch_size=32, label_mode='binary'
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    'dataset', validation_split=0.2, subset='validation',
    seed=123, image_size=(224,224), batch_size=32, label_mode='binary'
)

# 3) Classes
class_names = train_ds.class_names
print("Classes:", class_names)

# 4) Pipeline tf.data otimizado
train_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)
val_ds = val_ds.cache().prefetch(AUTOTUNE)

# 5) Data augmentation
data_augmentation = models.Sequential([
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
    layers.RandomContrast(0.1),
])

# 6) Cálculo de pesos de classe
labels = np.concatenate([y for x, y in train_ds], axis=0)
class_weights_raw = np.bincount(labels.astype(int).flatten())
total = labels.shape[0]
class_weights = {i: total/count for i, count in enumerate(class_weights_raw)}
print("Distribuição de classes:", class_weights_raw)
print("Pesos de classes:", class_weights)

# 7) Base model + fine-tuning
base_model = applications.MobileNetV2(
    input_shape=(224,224,3), include_top=False, weights='imagenet'
)
fine_tune_at = 100
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False
for layer in base_model.layers[fine_tune_at:]:
    layer.trainable = True

# 8) Construindo o modelo final
inputs = layers.Input(shape=(224,224,3))
x = data_augmentation(inputs)
x = applications.mobilenet_v2.preprocess_input(x)
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.BatchNormalization()(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(128, activation='relu')(x)
x = layers.Dropout(0.3)(x)
outputs = layers.Dense(1, activation='sigmoid')(x)
model = models.Model(inputs, outputs)

# 9) Otimizador e compile
lr_schedule = optimizers.schedules.ExponentialDecay(
    initial_learning_rate=1e-4, decay_steps=1000, decay_rate=0.9
)
optimizer = optimizers.Adam(learning_rate=lr_schedule)
model.compile(
    optimizer=optimizer,
    loss='binary_crossentropy',
    metrics=['accuracy', metrics.Precision(), metrics.Recall(), metrics.AUC(name='auc')]
)

# 10) Diretórios e callbacks
script_dir = os.path.dirname(os.path.abspath(__file__))
models_dir = os.path.join(script_dir, 'models')
os.makedirs(models_dir, exist_ok=True)

callbacks_list = [
    callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),
    callbacks.ModelCheckpoint(
        os.path.join(models_dir, 'best_model.keras'),
        monitor='val_auc', mode='max', save_best_only=True
    ),
    callbacks.TensorBoard(log_dir=os.path.join(models_dir, 'logs'))
]

# 11) Treinamento
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20,
    callbacks=callbacks_list,
    class_weight=class_weights
)

# 12) Plots de métricas
plt.figure(figsize=(12,5))
for idx, metric in enumerate(['loss', 'accuracy', 'auc']):
    plt.subplot(1, 3, idx+1)
    plt.plot(history.history[metric], label='treino')
    plt.plot(history.history[f'val_{metric}'], label='validação')
    plt.title(metric.capitalize())
    plt.xlabel('Época')
    plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(models_dir, 'metrics.png'))
plt.show()

# 13) Avaliação final
print("\nAvaliação Final:")
val_loss, val_acc, val_prec, val_rec, val_auc = model.evaluate(val_ds)
print(f"Perda: {val_loss:.4f}")
print(f"Acurácia: {val_acc:.4f}")
print(f"Precisão: {val_prec:.4f}")
print(f"Recall: {val_rec:.4f}")
print(f"AUC: {val_auc:.4f}")
print(f"F1-Score: {2 * (val_prec * val_rec) / (val_prec + val_rec):.4f}")

# 14) Matriz de confusão

y_true, y_pred = [], []
for images, labels in val_ds:
    preds = model.predict(images)
    preds = (preds > 0.5).astype(int).flatten()
    y_true.extend(labels.numpy().astype(int))
    y_pred.extend(preds)

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Matriz de Confusão')
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names, rotation=45)
plt.yticks(tick_marks, class_names)

thresh = cm.max() / 2.
for i, j in np.ndindex(cm.shape):
    plt.text(j, i, cm[i, j],
             horizontalalignment='center',
             color='white' if cm[i, j] > thresh else 'black')

plt.ylabel('Classe Real')
plt.xlabel('Classe Prevista')
plt.tight_layout()
plt.savefig(os.path.join(models_dir, 'confusion_matrix.png'))
plt.show()

# 15) Salvar modelo final
model.save(os.path.join(models_dir, 'modelo_final.keras'))
print("\nTreinamento concluído e modelo salvo em 'models/'!")
