# =============================================================================
# SISTEMA DE TREINAMENTO DE INTELIG√äNCIA ARTIFICIAL PARA CLASSIFICA√á√ÉO DE IMAGENS
# =============================================================================
# Este c√≥digo treina uma IA para classificar imagens como "Verdadeiros" ou "Falsos"

import datetime  # Para criar nomes √∫nicos de arquivos baseados na data/hora
import logging
# --- Configura√ß√£o Inicial e Supress√£o de Avisos ---
# Estas configura√ß√µes silenciam mensagens t√©cnicas desnecess√°rias durante o treinamento
import os
import warnings

# Configura√ß√µes para reduzir "polui√ß√£o visual" no terminal
os.environ[
    'TF_CPP_MIN_LOG_LEVEL'
] = '2'  # 0=tudo, 1=info, 2=avisos, 3=s√≥ erros
os.environ[
    'TF_DETERMINISTIC_OPS'
] = '1'   # Faz a IA ser mais "previs√≠vel" nos resultados
warnings.filterwarnings(
    'ignore', category=UserWarning
)    # Ignora avisos gerais
warnings.filterwarnings(
    'ignore', category=FutureWarning
)  # Ignora avisos de futuras vers√µes
logging.getLogger('tensorflow').setLevel(
    logging.ERROR
)    # S√≥ mostra erros do TensorFlow
logging.getLogger('keras').setLevel(
    logging.ERROR
)         # S√≥ mostra erros do Keras

# Importando as "ferramentas" que vamos usar
import tensorflow as tf  # Biblioteca principal para IA

tf.get_logger().setLevel(
    'ERROR'
)   # Mais uma configura√ß√£o para silenciar mensagens

import itertools  # Para fazer loops especiais
import random  # Para gerar n√∫meros aleat√≥rios

import matplotlib.pyplot as plt  # Para criar gr√°ficos bonitos
import numpy as np  # Para trabalhar com n√∫meros e matrizes
from sklearn.metrics import auc  # Para medir o qu√£o boa nossa IA ficou
from sklearn.metrics import classification_report, confusion_matrix, roc_curve
from tensorflow.keras import applications  # Pe√ßas para construir nossa IA
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import (  # "Assistentes" durante o treinamento
    EarlyStopping, ModelCheckpoint, TensorBoard)

# --- Hiperpar√¢metros e Configura√ß√µes Globais ---
# Pense nestes como "configura√ß√µes do jogo" - mudando eles, mudamos como a IA aprende

# === CONFIGURA√á√ïES DO DATASET (conjunto de imagens) ===
DATASET_DIR = 'dataset'  # Pasta onde est√£o nossas imagens de exemplo
IMAGE_SIZE = (
    64,
    64,
)  # Tamanho que todas as imagens ter√£o (largura x altura em pixels)
# Maior = mais detalhes, mas mais lento para processar
BATCH_SIZE = 8         # Quantas imagens a IA v√™ de uma vez (como tamanho da "colherada") - # Batches menores para melhor precis√£o
# Menor = aprende mais devagar mas com mais precis√£o
VALIDATION_SPLIT = (
    0.2  # 20% das imagens ser√£o usadas para "testar" a IA (n√£o para treinar)
)
SEED = 123             # "Semente" para garantir que os resultados sejam reproduz√≠veis

# === CONFIGURA√á√ïES DO TREINAMENTO ===
INITIAL_LR = 0.00005    # Taxa de aprendizado inicial - qu√£o "grandes" s√£o os ajustes que a IA faz
# Muito alto = aprende r√°pido mas pode "bagun√ßar", muito baixo = aprende devagar
DECAY_STEPS = 10000    # A cada quantos passos diminu√≠mos a taxa de aprendizado
DECAY_RATE = (
    0.9  # Por quanto multiplicamos a taxa (0.9 = reduz 10% a cada vez)
)
EPOCHS = 50  # Quantas vezes a IA vai "estudar" todo o conjunto de imagens
PATIENCE_EARLY_STOPPING = (
    10  # Se a IA n√£o melhorar por 7 √©pocas, paramos o treinamento
)
FINE_TUNE_AT_LAYER = 50     # A partir de qual camada vamos "ajustar finamente" a IA pr√©-treinada

# === CONFIGURA√á√ïES DA ARQUITETURA (estrutura da IA) ===
DENSE_UNITS_1 = (
    512  # Quantidade de "neur√¥nios" na primeira camada personalizada
)
DROPOUT_1 = (
    0.3  # Probabilidade de "desligar" neur√¥nios (previne decorar demais)
)
DENSE_UNITS_2 = 256    # Quantidade de neur√¥nios na segunda camada
DROPOUT_2 = 0.3        # Dropout da segunda camada

# --- Configura√ß√£o de Seeds para Reprodutibilidade ---
# Isso garante que toda vez que rodarmos o c√≥digo, teremos resultados similares
# √â como fixar a "sorte" dos dados aleat√≥rios
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# --- Prepara√ß√£o dos Diret√≥rios ---
# Criamos pastas para salvar nossos modelos e logs (registros do treinamento)
SCRIPT_DIR = os.path.dirname(
    os.path.abspath(__file__ if '__file__' in globals() else '.')
)
MODELS_DIR = os.path.join(
    SCRIPT_DIR, 'models'
)  # Pasta para salvar a IA treinada
LOGS_DIR = os.path.join(
    SCRIPT_DIR,
    'logs',
    'fit',
    datetime.datetime.now().strftime('%Y%m%d-%H%M%S'),
)  # Logs com timestamp
os.makedirs(MODELS_DIR, exist_ok=True)   # Cria a pasta se n√£o existir
os.makedirs(LOGS_DIR, exist_ok=True)     # Cria a pasta de logs

# --- Carregamento e Prepara√ß√£o do Dataset ---
# Aqui carregamos as imagens que v√£o "ensinar" nossa IA
print('\n--- Carregando Datasets ---')

# Carrega imagens para TREINAMENTO
# √â como preparar um monte de flashcards para estudar
train_ds = tf.keras.utils.image_dataset_from_directory(
    DATASET_DIR,  # De onde pegar as imagens
    labels='inferred',  # As pastas determinam as classes (ex: pasta "Verdadeiros", pasta "Falsos")
    label_mode='binary',  # Classifica√ß√£o bin√°ria: apenas 2 categorias (0 ou 1)
    validation_split=VALIDATION_SPLIT,  # Separa 20% para valida√ß√£o
    subset='training',  # Esta √© a parte de treino
    seed=SEED,  # Para reprodutibilidade
    image_size=IMAGE_SIZE,  # Redimensiona todas as imagens para o mesmo tamanho
    batch_size=BATCH_SIZE,  # Quantas imagens processar por vez
)

# Carrega imagens para VALIDA√á√ÉO
# S√£o imagens que a IA nunca viu - usamos para testar se ela realmente aprendeu
val_ds = tf.keras.utils.image_dataset_from_directory(
    DATASET_DIR,
    labels='inferred',
    label_mode='binary',
    validation_split=VALIDATION_SPLIT,
    subset='validation',  # Esta √© a parte de valida√ß√£o (teste)
    seed=SEED,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
)

# Descobrir quais s√£o as classes (categorias) encontradas
CLASS_NAMES = train_ds.class_names
print(f'Classes encontradas: {CLASS_NAMES}')

# Verifica√ß√£o importante: garantir que as classes est√£o na ordem correta
# Para classifica√ß√£o bin√°ria, normalmente 0="Falso" e 1="Verdadeiro"
if CLASS_NAMES[0] != 'Falsos' or CLASS_NAMES[1] != 'Verdadeiros':
    print(f'Aviso: Ordem das classes detectada: {CLASS_NAMES}')
    print(
        "Esperado: ['Verdadeiros', 'Falsos'] para classifica√ß√£o bin√°ria correta"
    )

# Mostra quantas imagens temos para treinar e validar
print(
    f'Total de amostras de treino: {tf.data.experimental.cardinality(train_ds).numpy() * BATCH_SIZE}'
)
print(
    f'Total de amostras de valida√ß√£o: {tf.data.experimental.cardinality(val_ds).numpy() * BATCH_SIZE}'
)

# --- Data Augmentation (Aumento de Dados) ---
# T√©cnica para "multiplicar" nossas imagens criando varia√ß√µes
# √â como tirar fotos do mesmo objeto de √¢ngulos diferentes
# Isso ajuda a IA a n√£o "decorar" as imagens espec√≠ficas, mas aprender padr√µes gerais
data_augmentation = tf.keras.Sequential(
    [
        layers.RandomFlip(
            'horizontal', seed=SEED
        ),  # Espelha a imagem horizontalmente (√†s vezes)
        layers.RandomRotation(
            0.05, seed=SEED
        ),  # Gira a imagem levemente (at√© 5%)
        layers.RandomZoom(0.15, seed=SEED),  # Zoom in/out aleat√≥rio (at√© 15%)
        #layers.RandomContrast(0.1, seed=SEED),  pode mascarar motion blur
    ],
    name='data_augmentation',
)

# --- Otimiza√ß√£o de Performance do Dataset ---
# Configura√ß√µes para que o carregamento das imagens seja mais r√°pido
AUTOTUNE = tf.data.AUTOTUNE  # Deixa o TensorFlow otimizar automaticamente
train_ds = train_ds.cache().prefetch(
    buffer_size=AUTOTUNE
)  # Cache + carregamento antecipado
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# --- C√°lculo de Pesos de Classe (para lidar com desbalanceamento) ---
# Se tivermos muito mais imagens de uma classe que de outra, isso equilibra o aprendizado
print('\n--- Calculando Pesos de Classe ---')

# Primeiro, precisamos contar quantas imagens temos de cada classe
labels_list = []  # Lista para armazenar todos os r√≥tulos (0s e 1s)

# Percorre todo o dataset de treino coletando os r√≥tulos
for _, labels_batch in train_ds:  # Para cada lote de imagens e seus r√≥tulos
    labels_list.append(labels_batch.numpy())  # Adiciona os r√≥tulos √† lista

# Junta todos os r√≥tulos em uma √∫nica lista
labels_array = np.concatenate(labels_list, axis=0).astype(int).flatten()

# Se conseguimos coletar os r√≥tulos, calculamos os pesos
if labels_array.size > 0:
    class_counts = np.bincount(labels_array)  # Conta quantos 0s e 1s temos

    if len(class_counts) == len(
        CLASS_NAMES
    ):  # Se temos contagens para todas as classes
        total_samples = np.sum(class_counts)   # Total de amostras

        # F√≥rmula para calcular pesos: classes com menos amostras ganham peso maior
        # Isso faz a IA dar mais aten√ß√£o para a classe minorit√°ria
        class_weights = {
            i: total_samples / (count * len(CLASS_NAMES))
            for i, count in enumerate(class_counts)
            if count > 0
        }

        print(
            f'Distribui√ß√£o de classes no treino (antes do peso): {dict(enumerate(class_counts))}'
        )
        print(f'Pesos de classes aplicados: {class_weights}')
    else:
        print(
            'Aviso: N√∫mero de classes contadas n√£o corresponde ao esperado. N√£o aplicando pesos de classe.'
        )
        class_weights = None
else:
    print(
        'Aviso: N√£o foi poss√≠vel extrair labels para c√°lculo de pesos. N√£o aplicando pesos de classe.'
    )
    class_weights = None

# --- Constru√ß√£o do Modelo com Fine-Tuning ---
print('\n--- Construindo Modelo ---')

# Camada de normaliza√ß√£o: converte imagens de 0-255 para -1 a 1
# As IAs pr√©-treinadas esperam este formato espec√≠fico
rescale_layer = layers.Rescaling(
    1.0 / 255, offset=-1, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)
)

# Modelo base: MobileNetV2 - uma IA j√° treinada em milh√µes de imagens
# √â como contratar um professor que j√° sabe reconhecer formas b√°sicas
base_model = applications.MobileNetV2(
    input_shape=(
        IMAGE_SIZE[0],
        IMAGE_SIZE[1],
        3,
    ),  # Formato das nossas imagens
    include_top=False,  # Remove a "cabe√ßa" original - vamos colocar nossa pr√≥pria
    weights='imagenet',  # Usa pesos de uma IA treinada no ImageNet (milh√µes de imagens)
)

# Inicialmente, "congelamos" o modelo base
# Significa que n√£o vamos mudar o que ele j√° aprendeu (ainda)
base_model.trainable = False

# Fine-tuning: permite que as camadas finais do modelo base sejam ajustadas
# √â como permitir que o professor adapte algumas t√©cnicas para nosso problema espec√≠fico
for layer in base_model.layers[FINE_TUNE_AT_LAYER:]:
    layer.trainable = True  # Permite treinar esta camada

print(
    f'Modelo base: {len(base_model.layers)} camadas. Fine-tuning a partir da camada {FINE_TUNE_AT_LAYER}.'
)
num_trainable_layers_base = sum(
    1 for layer in base_model.layers if layer.trainable
)
print(
    f'N√∫mero de camadas trein√°veis no modelo base: {num_trainable_layers_base}'
)


# Adicione ap√≥s rescale_layer
grayscale_layer = layers.Lambda(
    lambda x: tf.image.rgb_to_grayscale(x),
    name='rgb_to_grayscale'
)

# Converte de volta para 3 canais (compatibilidade com MobileNetV2)
grayscale_to_rgb = layers.Lambda(
    lambda x: tf.concat([x, x, x], axis=-1),
    name='grayscale_to_rgb'
)

# Constru√ß√£o do modelo completo: modelo base + nossas camadas personalizadas
# √â como empilhar blocos de Lego - cada camada processa a informa√ß√£o da anterior
model = models.Sequential([
    rescale_layer,           # 1. Normaliza as imagens  
    data_augmentation,       # 2. Aplica varia√ß√µes (antes do grayscale!)
    grayscale_layer,         # 3. Converte para escala de cinza
    grayscale_to_rgb,        # 4. Volta para 3 canais
    base_model,              # 5. Modelo MobileNetV2 pr√©-treinado
    layers.GlobalAveragePooling2D(),
    layers.BatchNormalization(), 
    layers.Dense(DENSE_UNITS_1, activation='relu'),
    layers.Dropout(DROPOUT_1),
    layers.Dense(DENSE_UNITS_2, activation='relu'),
    layers.Dropout(DROPOUT_2),
    layers.Dense(1, activation='sigmoid'),
], name='Custom_MobileNetV2')

# --- Compila√ß√£o do Modelo ---
# Aqui definimos como a IA vai aprender e quais m√©tricas vamos acompanhar

# Learning Rate Schedule: diminui gradualmente a taxa de aprendizado
# √â como come√ßar estudando com passos grandes e depois com passos menores para precis√£o
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=INITIAL_LR,  # Taxa inicial
    decay_steps=DECAY_STEPS,  # A cada quantos passos diminui
    decay_rate=DECAY_RATE,  # Por quanto multiplica (0.9 = reduz 10%)
    staircase=True,  # Muda em intervalos discretos
)

# Otimizador: algoritmo que ajusta os "pesos" da IA para melhorar
# Adam √© um dos melhores - funciona bem na maioria dos casos
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

# Compila√ß√£o: "monta" o modelo com todas as configura√ß√µes
model.compile(
    optimizer=optimizer,  # Como vai aprender
    loss='binary_crossentropy',  # Como mede o "erro" (para 2 classes)
    metrics=[
        'accuracy',  # M√©tricas que queremos acompanhar:
        tf.keras.metrics.Precision(
            name='precision'
        ),  # Precis√£o: de todas que disse "sim", quantas estavam certas?
        tf.keras.metrics.Recall(name='recall'),
    ],  # Recall: de todas que eram "sim", quantas encontrou?
)

# Mostra a estrutura do modelo
model.summary()

# --- Callbacks ---
# "Assistentes" que monitoram o treinamento e tomam decis√µes autom√°ticas
print('\n--- Configurando Callbacks ---')

# EarlyStopping: para o treinamento se n√£o houver melhora
# √â como um t√©cnico que manda parar o treino se o atleta n√£o est√° melhorando
early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitora a "perda" na valida√ß√£o
    patience=PATIENCE_EARLY_STOPPING,  # Espera 7 √©pocas sem melhora
    verbose=1,  # Informa quando parar
    restore_best_weights=True,  # Volta para o melhor modelo encontrado
)

# ModelCheckpoint: salva automaticamente o melhor modelo (por acur√°cia)
# √â como tirar uma foto sempre que o atleta quebra um recorde
model_checkpoint_accuracy = ModelCheckpoint(
    filepath=os.path.join(
        MODELS_DIR, 'best_model_val_accuracy.keras'
    ),  # Onde salvar
    save_best_only=True,  # S√≥ salva se for melhor que o anterior
    monitor='val_accuracy',  # Monitora a acur√°cia de valida√ß√£o
    mode='max',  # Quer o valor M√ÅXIMO
    verbose=1,  # Informa quando salva
)

# Outro checkpoint para salvar o modelo com melhor precis√£o
model_checkpoint_f1 = ModelCheckpoint(
    filepath=os.path.join(MODELS_DIR, 'best_model_val_precision.keras'),
    save_best_only=True,
    monitor='val_precision',  # Monitora a precis√£o
    mode='max',
    verbose=1,
)

# TensorBoard: cria gr√°ficos bonitos para visualizar o progresso
# √â como um painel de controle que mostra tudo o que est√° acontecendo
tensorboard_callback = TensorBoard(
    log_dir=LOGS_DIR,  # Onde salvar os logs
    histogram_freq=1,  # Com que frequ√™ncia salvar histogramas
    write_graph=True,  # Salva o gr√°fico da arquitetura do modelo
)

# Lista com todos os callbacks
callbacks_list = [
    early_stopping,
    model_checkpoint_accuracy,
    model_checkpoint_f1,
    tensorboard_callback,
]

# --- Treinamento do Modelo ---
# AQUI √â ONDE A M√ÅGICA ACONTECE! A IA realmente aprende
print('\n--- Iniciando Treinamento ---')

# O m√©todo fit() √© onde a IA "estuda" as imagens
history = model.fit(
    train_ds,  # Dados de treinamento (imagens + r√≥tulos)
    validation_data=val_ds,  # Dados para testar durante o treino
    epochs=EPOCHS,  # Quantas vezes vai estudar todo o dataset
    callbacks=callbacks_list,  # Assistentes que monitoram o processo
    class_weight=class_weights
    if class_weights
    else None,  # Pesos para balancear classes
)

# --- Plotar Curvas de Treinamento ---
# Cria gr√°ficos para visualizar como foi o aprendizado
print('\n--- Gerando Gr√°ficos de Treinamento ---')

plt.figure(figsize=(14, 6))  # Cria uma figura com tamanho espec√≠fico

# Primeiro gr√°fico: Loss (Perda)
# Mostra como o "erro" da IA diminuiu ao longo do tempo
plt.subplot(1, 2, 1)  # Primeiro gr√°fico de uma linha com 2 colunas
plt.plot(history.history['loss'], label='Perda Treino')
plt.plot(history.history['val_loss'], label='Perda Valida√ß√£o')
plt.title('Perda (Loss) Durante Treinamento')
plt.xlabel('√âpoca')
plt.ylabel('Perda')
plt.legend()

# Segundo gr√°fico: M√©tricas (Acur√°cia, Precis√£o, Recall)
# Mostra como a performance da IA melhorou
plt.subplot(1, 2, 2)  # Segundo gr√°fico
plt.plot(history.history['accuracy'], label='Acur√°cia Treino')
plt.plot(history.history['val_accuracy'], label='Acur√°cia Valida√ß√£o')
plt.plot(history.history.get('precision', []), label='Precis√£o Treino')
plt.plot(history.history.get('val_precision', []), label='Precis√£o Valida√ß√£o')
plt.plot(history.history.get('recall', []), label='Recall Treino')
plt.plot(history.history.get('val_recall', []), label='Recall Valida√ß√£o')
plt.title('M√©tricas Durante Treinamento')
plt.xlabel('√âpoca')
plt.ylabel('Valor da M√©trica')
plt.legend()

plt.tight_layout()  # Organiza os gr√°ficos de forma bonita
plt.savefig(os.path.join(MODELS_DIR, 'training_history.png'))  # Salva a imagem
plt.show()  # Mostra os gr√°ficos na tela

# --- Avalia√ß√£o Final ---
# Agora vamos testar o qu√£o boa nossa IA ficou
print(
    "\n--- Avalia√ß√£o do Modelo com Melhor 'val_loss' (Restaurado por EarlyStopping) ---"
)

# Testa o modelo nas imagens de valida√ß√£o
val_loss, val_acc, val_prec, val_rec = model.evaluate(val_ds, verbose=1)

# Mostra os resultados de forma clara
print(f'Perda Valida√ß√£o: {val_loss:.4f}')         # Quanto menor, melhor
print(
    f'Acur√°cia Valida√ß√£o: {val_acc:.4f}'
)       # % de acertos (0-1, quanto maior melhor)
print(
    f'Precis√£o Valida√ß√£o: {val_prec:.4f}'
)      # Das que disse "sim", quantas eram realmente "sim"?
print(
    f'Recall Valida√ß√£o: {val_rec:.4f}'
)         # Das que eram "sim", quantas conseguiu encontrar?

# Calcula F1-Score: m√©dia harm√¥nica entre Precis√£o e Recall
if (val_prec + val_rec) > 0:
    f1_score = 2 * (val_prec * val_rec) / (val_prec + val_rec)
    print(f'F1-Score Valida√ß√£o: {f1_score:.4f}')
else:
    print('F1-Score Valida√ß√£o: 0.0000 (divis√£o por zero evitada)')

# Salva o modelo treinado
model.save(os.path.join(MODELS_DIR, 'FrameQC_model.keras'))
print(
    f"Modelo com melhor 'val_loss' salvo em: {os.path.join(MODELS_DIR, 'FrameQC_model.keras')}"
)

# Avalia tamb√©m o modelo que teve a melhor acur√°cia durante o treinamento
best_accuracy_model_path = os.path.join(
    MODELS_DIR, 'best_model_val_accuracy.keras'
)
if os.path.exists(best_accuracy_model_path):
    print(
        "\n--- Avalia√ß√£o do Modelo com Melhor 'val_accuracy' (De ModelCheckpoint) ---"
    )

    # Carrega o modelo salvo automaticamente
    model_best_acc = tf.keras.models.load_model(best_accuracy_model_path)

    # Testa este modelo
    val_loss_ba, val_acc_ba, val_prec_ba, val_rec_ba = model_best_acc.evaluate(
        val_ds, verbose=1
    )

    # Mostra os resultados
    print(f'Perda Valida√ß√£o (Melhor Acur√°cia): {val_loss_ba:.4f}')
    print(f'Acur√°cia Valida√ß√£o (Melhor Acur√°cia): {val_acc_ba:.4f}')
    print(f'Precis√£o Valida√ß√£o (Melhor Acur√°cia): {val_prec_ba:.4f}')
    print(f'Recall Valida√ß√£o (Melhor Acur√°cia): {val_rec_ba:.4f}')

    if (val_prec_ba + val_rec_ba) > 0:
        f1_score_ba = (
            2 * (val_prec_ba * val_rec_ba) / (val_prec_ba + val_rec_ba)
        )
        print(f'F1-Score Valida√ß√£o (Melhor Acur√°cia): {f1_score_ba:.4f}')
    else:
        print(
            'F1-Score Valida√ß√£o (Melhor Acur√°cia): 0.0000 (divis√£o por zero evitada)'
        )

    # --- Matriz de Confus√£o e Relat√≥rio de Classifica√ß√£o ---
    # A matriz de confus√£o √© como uma "tabela de acertos e erros"
    # Mostra exatamente onde nossa IA est√° errando
    print(
        '\n--- Gerando Matriz de Confus√£o para Modelo de Melhor Acur√°cia ---'
    )

    y_true_list = []        # Lista das respostas corretas
    y_pred_probs_list = []  # Lista das "apostas" da IA (probabilidades)

    # Para cada lote de imagens de valida√ß√£o
    for images_batch, labels_batch in val_ds:
        # Pede para a IA fazer predi√ß√µes
        predictions_batch = model_best_acc.predict_on_batch(images_batch)

        # Guarda as probabilidades que a IA calculou
        y_pred_probs_list.extend(predictions_batch.flatten())

        # Guarda as respostas corretas
        y_true_list.extend(labels_batch.numpy().astype(int).flatten())

    # --- Otimiza√ß√£o de Threshold para Maximizar Precis√£o ---
    # Por padr√£o, se a IA diz >0.5, classificamos como "1" (Verdadeiro)
    # Mas podemos ajustar este limite para ter melhor precis√£o
    print('\n--- Otimizando Threshold para M√°xima Precis√£o ---')

    # Calcula a curva ROC - mostra como a IA performa em diferentes thresholds
    fpr, tpr, thresholds = roc_curve(y_true_list, y_pred_probs_list)
    roc_auc = auc(fpr, tpr)  # AUC: √°rea sob a curva (quanto maior, melhor)
    print(f'AUC: {roc_auc:.4f}')

    # Procura o melhor threshold (limite) para maximizar precis√£o
    from sklearn.metrics import precision_score

    best_threshold = 0.5    # Come√ßamos com o padr√£o
    best_precision = 0      # Melhor precis√£o encontrada

    # Testa diferentes thresholds entre 0.3 e 0.8
    for threshold in np.arange(
        0.3, 0.8, 0.05
    ):  # De 0.3 a 0.8 em passos de 0.05
        # Converte probabilidades em decis√µes usando este threshold
        y_pred_thresh = [
            1 if prob > threshold else 0 for prob in y_pred_probs_list
        ]

        # Calcula a precis√£o com este threshold
        precision = precision_score(y_true_list, y_pred_thresh)

        # Se √© melhor que o anterior, salva
        if precision > best_precision:
            best_precision = precision
            best_threshold = threshold

    print(
        f'Melhor threshold para precis√£o: {best_threshold:.2f} (Precis√£o: {best_precision:.4f})'
    )

    # Gera predi√ß√µes com ambos os thresholds para comparar
    y_pred_classes = [
        1 if prob > 0.5 else 0 for prob in y_pred_probs_list
    ]           # Threshold padr√£o
    y_pred_optimized = [
        1 if prob > best_threshold else 0 for prob in y_pred_probs_list
    ]  # Threshold otimizado

    # Fun√ß√£o para criar gr√°ficos da matriz de confus√£o
    def plot_confusion_matrix(
        cm, class_names_list, title='Matriz de Confus√£o', save_path=None
    ):
        """
        Cria um gr√°fico visual da matriz de confus√£o

        A matriz de confus√£o √© uma tabela que mostra:
        - Linha: classe real (o que deveria ser)
        - Coluna: classe predita (o que a IA disse)
        - Diagonal principal: acertos
        - Fora da diagonal: erros
        """
        plt.figure(figsize=(8, 6))
        plt.imshow(
            cm, interpolation='nearest', cmap=plt.cm.Blues
        )  # Cria o gr√°fico com cores azuis
        plt.title(title)
        plt.colorbar()  # Barra de cores para entender os valores

        # Configura os eixos com os nomes das classes
        tick_marks = np.arange(len(class_names_list))
        plt.xticks(
            tick_marks, class_names_list, rotation=45
        )  # R√≥tulos no eixo X
        plt.yticks(
            tick_marks, class_names_list
        )               # R√≥tulos no eixo Y

        # Adiciona os n√∫meros dentro de cada c√©lula da matriz
        thresh = cm.max() / 2.0  # Threshold para decidir cor do texto
        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
            plt.text(
                j,
                i,
                format(cm[i, j], 'd'),  # N√∫mero formatado
                horizontalalignment='center',
                color='white' if cm[i, j] > thresh else 'black',
            )  # Cor do texto

        plt.tight_layout()
        plt.ylabel('Classe Real')      # R√≥tulo do eixo Y
        plt.xlabel('Classe Prevista')  # R√≥tulo do eixo X

        if save_path:
            plt.savefig(save_path)  # Salva a imagem se especificado
        plt.show()

    # Cria matriz de confus√£o com threshold padr√£o (0.5)
    cm = confusion_matrix(y_true_list, y_pred_classes)
    plot_confusion_matrix(
        cm,
        CLASS_NAMES,
        title='Matriz de Confus√£o (Threshold 0.5)',
        save_path=os.path.join(MODELS_DIR, 'confusion_matrix_best_acc.png'),
    )

    # Relat√≥rio detalhado de classifica√ß√£o (threshold padr√£o)
    print('\nRelat√≥rio de Classifica√ß√£o (Threshold 0.5):')
    print(
        classification_report(
            y_true_list, y_pred_classes, target_names=CLASS_NAMES
        )
    )

    # Cria matriz de confus√£o com threshold otimizado
    cm_opt = confusion_matrix(y_true_list, y_pred_optimized)
    plot_confusion_matrix(
        cm_opt,
        CLASS_NAMES,
        title=f'Matriz de Confus√£o (Threshold {best_threshold:.2f})',
        save_path=os.path.join(MODELS_DIR, 'confusion_matrix_optimized.png'),
    )

    # Relat√≥rio detalhado de classifica√ß√£o (threshold otimizado)
    print(f'\nRelat√≥rio de Classifica√ß√£o (Threshold {best_threshold:.2f}:')
    print(
        classification_report(
            y_true_list, y_pred_optimized, target_names=CLASS_NAMES
        )
    )

else:
    print(
        f'Modelo {best_accuracy_model_path} n√£o encontrado. Pulando avalia√ß√£o e matriz de confus√£o.'
    )

print('\n--- Treinamento e Avalia√ß√£o Conclu√≠dos ---')
print('üéâ Parab√©ns! Sua IA foi treinada com sucesso!')
print('üìä Verifique os gr√°ficos e m√©tricas para entender como ela performou.')
print("üíæ Os modelos foram salvos na pasta 'models' para uso futuro.")
